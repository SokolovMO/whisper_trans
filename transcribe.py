import whisper
from pathlib import Path
from datetime import datetime
import sys

def select_model_interactively():
    models = ["tiny", "base", "small", "medium", "large"]
    print("ðŸ“¦ Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Whisper:\n")
    for i, name in enumerate(models, start=1):
        print(f"{i}. {name}")
    try:
        choice = int(input("\nÐ’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (1-5): "))
        if 1 <= choice <= 5:
            return models[choice - 1]
        else:
            print("âš ï¸ Ð½ÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: base")
            return "base"
    except:
        print("âš ï¸ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð²Ñ‹Ð±Ð¾Ñ€, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: base")
        return "base"

def transcribe_audio(file_path: Path, model_name="base"):
    print(f"\nðŸ“‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»: {file_path}")
    if not file_path.exists():
        print(f"âŒ Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {file_path}")
        return

    try:
        print(f"ðŸ“¦ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ whisper: {model_name}")
        model = whisper.load_model(model_name)

        print("ðŸ§  Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð°Ñ†Ð¸ÑŽ...")
        result = model.transcribe(str(file_path))

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("results_transcribe")
        output_dir.mkdir(exist_ok=True)
        output_plain = output_dir / f"{file_path.stem}_{timestamp}_transcription.txt"
        output_timed = output_dir / f"{file_path.stem}_{timestamp}_with_timestamps.txt"
        # output_plain = file_path.with_name(f"{file_path.stem}_{timestamp}_transcription.txt")
        output_timed = file_path.with_name(f"{file_path.stem}_{timestamp}_with_timestamps.txt")

        with open(output_plain, "w", encoding="utf-8") as f:
            f.write(result["text"])

        with open(output_timed, "w", encoding="utf-8") as f:
            for segment in result.get("segments", []):
                f.write(f"[{segment['start']:.2f} - {segment['end']:.2f}] {segment['text']}\n")

        print(f"âœ… Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°.\nðŸ“ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾:\n- {output_plain.name}\n- {output_timed.name}")

    except Exception as e:
        print(f"âŒ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}")

def main():
    args = sys.argv[1:]

    if not args:
        print("â— Ð¿ÐµÑ€ÐµÑ‚Ð°Ñ‰Ð¸ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» Ð½Ð° ÑÐºÑ€Ð¸Ð¿Ñ‚, Ð¸Ð»Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð² Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ…\n")
        return

    file_path = Path(args[0])

    if len(args) > 1:
        model_name = args[1]
    else:
        model_name = select_model_interactively()

    transcribe_audio(file_path, model_name=model_name)

if __name__ == "__main__":
    main()
